{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1955f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import nltk\n",
    "import xlsxwriter\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b5476d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           abandon\n",
       "1             abase\n",
       "2             abash\n",
       "3             abate\n",
       "4        abbreviate\n",
       "           ...     \n",
       "3036           wily\n",
       "3037        wiretap\n",
       "3038        wistful\n",
       "3039          wrest\n",
       "3040    wrongheaded\n",
       "Name: word, Length: 3041, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_words = pd.read_csv(r\"C:\\Users\\singe\\660project\\data\\advanced_word.csv\")['word']\n",
    "adv_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ae3374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def tokenize(doc):\n",
    "\n",
    "    tokens =[]\n",
    "\n",
    "    for token in nlp(doc):\n",
    "          # remove stopwords\n",
    "          #if token.is_stop:\n",
    "           #continue\n",
    "\n",
    "          # remove punctuation\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "\n",
    "          # lemmatize & lower the capital letter\n",
    "        tokens.append(token.lemma_.lower())\n",
    "\n",
    "        # remove empty unigrams\n",
    "    tokens = [token.strip() for token in tokens if token.strip() != '']\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a06746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_rate(excel, sheet, col):\n",
    "    adv_words = pd.read_csv(r\"C:\\Users\\singe\\660project\\data\\advanced_word.csv\")['word'].tolist()\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(excel)\n",
    "    table = workbook[sheet]\n",
    "    col_content = table[col]\n",
    "    \n",
    "    lis = []\n",
    "    for cell in col_content:\n",
    "        if cell != None:\n",
    "            lis.append(cell.value)\n",
    "    \n",
    "    rate = None\n",
    "    i = 0\n",
    "    total_word = 0\n",
    "    for doc in lis:\n",
    "        if doc != None:\n",
    "            tokens = tokenize(doc)\n",
    "            total_word += len(tokens)\n",
    "            for token in tokens:\n",
    "                if token in adv_words:\n",
    "                    i += 1\n",
    "    \n",
    "    rate = i/total_word\n",
    "    return rate\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88a8e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_rate = advanced_rate(r\"C:\\Users\\singe\\660project\\data\\total data\\sented_aud_adv.xlsx\",'sented_aud','B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30100acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02325320362922084"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "866212d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03672388632294754"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cri_rate = advanced_rate(r\"C:\\Users\\singe\\660project\\data\\total data\\sented_crit_adv.xlsx\",'sheet2','B')\n",
    "cri_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68e101b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def tokenize_stop(doc):\n",
    "\n",
    "    tokens =[]\n",
    "\n",
    "    for token in nlp(doc):\n",
    "          # remove stopwords\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "\n",
    "          # remove punctuation\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "\n",
    "          # lemmatize & lower the capital letter\n",
    "        tokens.append(token.lemma_.lower())\n",
    "\n",
    "        # remove empty unigrams\n",
    "    tokens = [token.strip() for token in tokens if token.strip() != '']\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "979f7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_rate_stop(excel, sheet, col):\n",
    "    adv_words = pd.read_csv(r\"C:\\Users\\singe\\660project\\data\\advanced_word.csv\")['word'].tolist()\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(excel)\n",
    "    table = workbook[sheet]\n",
    "    col_content = table[col]\n",
    "    \n",
    "    lis = []\n",
    "    for cell in col_content:\n",
    "        if cell != None:\n",
    "            lis.append(cell.value)\n",
    "    \n",
    "    rate = None\n",
    "    i = 0\n",
    "    total_word = 0\n",
    "    for doc in lis:\n",
    "        if doc != None:\n",
    "            tokens = tokenize_stop(doc)\n",
    "            total_word += len(tokens)\n",
    "            for token in tokens:\n",
    "                if token in adv_words:\n",
    "                    i += 1\n",
    "    \n",
    "    rate = i/total_word\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebcd32b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04933048647876368"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_rate_stop = advanced_rate_stop(r\"C:\\Users\\singe\\660project\\data\\total data\\sented_aud_adv.xlsx\",'sented_aud','B')\n",
    "aud_rate_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c8cf8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07498771196854263"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cri_rate_stop = advanced_rate_stop(r\"C:\\Users\\singe\\660project\\data\\total data\\sented_crit_adv.xlsx\",'sheet2','B')\n",
    "cri_rate_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06c3e6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.579304379238263"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cri_rate-aud_rate)/aud_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fb2e5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5201089087338344"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cri_rate_stop-aud_rate_stop)/aud_rate_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac0d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
